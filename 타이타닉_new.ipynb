{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 캐글 타이타닉 : https://www.kaggle.com/competitions/titanic/overview\n",
    "### 목표 : 전처리 방법 변경 및 모델을 Tensorflow 딥러닝 모델로 변경하여 제출 후 스코어 0.8 이상 도달하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_o = pd.read_csv('train.csv')\n",
    "test_o = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # 이름으로부터 타이틀 추출\n",
    "    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "    title_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \n",
    "                    \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3,\"Countess\": 3,\n",
    "                    \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3, \"Mme\": 3,\"Capt\": 3,\"Sir\": 3 }\n",
    "    df['Title'] = df['Title'].map(title_mapping)\n",
    "\n",
    "    # 나이 결측치 처리\n",
    "    # fill missing age with median age for each title (Mr, Mrs, Miss, Others)\n",
    "    df['Age'] = df['Age'].fillna(df.groupby('Title')['Age'].transform('median'))\n",
    "\n",
    "    # Embarked 결측치 처리\n",
    "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "    df['Embarked'] = df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "\n",
    "    # 범주형 변수 처리\n",
    "    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "    df.loc[df['Age'] <= 16, 'Age'] = 0\n",
    "    df.loc[(df['Age'] > 16) & (df['Age'] <= 26), 'Age'] = 1\n",
    "    df.loc[(df['Age'] > 26) & (df['Age'] <= 36), 'Age'] = 2\n",
    "    df.loc[(df['Age'] > 36) & (df['Age'] <= 62), 'Age'] = 3\n",
    "    df.loc[df['Age'] > 62, 'Age'] = 4\n",
    "\n",
    "    # 가족 수 계산\n",
    "    df['Family'] = df['SibSp'] + df['Parch'] + 1\n",
    "\n",
    "    # Pclass별 Cabin 최빈값으로 결측치 채우기\n",
    "    df['Cabin'] = df.groupby('Pclass')['Cabin'].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else 'U'))\n",
    "    # Cabin 데이터 중 첫번째 알파벳만 처리\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "\n",
    "    # 원핫 인코딩을 사용\n",
    "    df = pd.get_dummies(df, columns=['Cabin'], prefix='Cabin')\n",
    "\n",
    "    # 원-핫 인코딩된 Cabin 열을 자동으로 포함하여 features 리스트 생성\n",
    "    cabin_columns = [col for col in df.columns if col.startswith('Cabin_')]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터 통합\n",
    "train_o['is_train'] = 1  # 훈련 데이터 구분용\n",
    "test_o['is_train'] = 0   # 테스트 데이터 구분용\n",
    "test_o['Survived'] = -1  # Survived 열 추가, 이후 분리 시 제거\n",
    "\n",
    "combined = pd.concat([train_o, test_o], ignore_index=True)\n",
    "\n",
    "# 전처리 함수 적용\n",
    "combined = preprocess_data(combined)\n",
    "\n",
    "# 다시 훈련 데이터와 테스트 데이터로 분리\n",
    "train = combined[combined['is_train'] == 1].drop(columns=['is_train'])\n",
    "test = combined[combined['is_train'] == 0].drop(columns=['is_train', 'Survived'])\n",
    "y = train['Survived']\n",
    "train = train.drop(columns=['Survived'])\n",
    "\n",
    "train = train.drop(columns=['PassengerId', 'Name', 'Ticket', 'Fare', 'SibSp', 'Parch'])\n",
    "test = test.drop(columns=['PassengerId', 'Name', 'Ticket', 'Fare', 'SibSp', 'Parch'])\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train)\n",
    "test_scaled = scaler.transform(test)\n",
    "\n",
    "# PyTorch 텐서로 변환\n",
    "X_tensor = torch.tensor(train_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(test_scaled, dtype=torch.float32)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tensor, y_tensor, test_size=0.1, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "class TitanicNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(TitanicNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "model = TitanicNet(input_size=train.shape[1])\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습 설정\n",
    "num_epochs = 1000\n",
    "batch_size = 256\n",
    "best_val_accuracy = 0\n",
    "\n",
    "train_accuracies = []  # 각 에폭의 train accuracy 값을 추가\n",
    "val_accuracies = []    # 각 에폭의 val accuracy 값을 추가\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 학습 모드 설정\n",
    "    model.train()\n",
    "    permutation = torch.randperm(X_train.size()[0])\n",
    "\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    \n",
    "    # 미니배치 학습\n",
    "    for i in range(0, X_train.size()[0], batch_size):\n",
    "        indices = permutation[i:i + batch_size]\n",
    "        batch_x, batch_y = X_train[indices], y_train[indices]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Train loss와 accuracy 계산\n",
    "        train_loss += loss.item() * batch_x.size(0)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        correct_train += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    # 에폭별 평균 train loss와 accuracy 계산\n",
    "    train_loss /= X_train.size(0)\n",
    "    train_accuracy = correct_train / X_train.size(0)\n",
    "\n",
    "    # 검증 모드 설정\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val)\n",
    "        val_loss = criterion(val_outputs, y_val).item()\n",
    "        val_predicted = (val_outputs > 0.5).float()\n",
    "        val_accuracy = accuracy_score(y_val, val_predicted)\n",
    "    \n",
    "    # 에폭별 결과 출력\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    # 최적의 모델 저장\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "\n",
    "    # 학습 및 검증 정확도 계산 코드 ...\n",
    "    train_accuracies.append(train_accuracy)  # train_accuracy는 각 에폭에서 계산된 값\n",
    "    val_accuracies.append(val_accuracy)      # val_accuracy는 각 에폭에서 계산된 값\n",
    "\n",
    "\n",
    "print(f\"Best model saved with val_accuracy: {best_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 그래프 그리기\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(num_epochs), train_accuracies, label=\"Train Accuracy\", linestyle=\"-\", marker=\"o\", markersize=3)\n",
    "plt.plot(range(num_epochs), val_accuracies, label=\"Validation Accuracy\", linestyle=\"-\", marker=\"x\", markersize=3)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Train and Validation Accuracy over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 예측\n",
    "best_model = TitanicNet(input_size=train.shape[1])\n",
    "best_model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "best_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_outputs = best_model(X_test_tensor)\n",
    "    test_predicted = (test_outputs > 0.5).float().squeeze()\n",
    "\n",
    "# 제출 파일 생성\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_o['PassengerId'],\n",
    "    'Survived': test_predicted.int().numpy()\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('Prediction completed and saved to submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
